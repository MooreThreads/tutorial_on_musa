import gradio as gr
import requests
import json
import argparse


def parse_args():
    # åˆ›å»º ArgumentParser å¯¹è±¡
    parser = argparse.ArgumentParser(description="Start the vLLM server.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--ip", 
        type=str, 
        default="0.0.0.0",  # å¦‚æœæ²¡æœ‰ä¼ å…¥--ipï¼Œä½¿ç”¨é»˜è®¤å€¼
        help="IP address to bind to (default: 0.0.0.0)"
    )

    parser.add_argument(
        "--port", 
        type=str, 
        default="8000",  # å¦‚æœæ²¡æœ‰ä¼ å…¥--portï¼Œä½¿ç”¨é»˜è®¤å€¼
        help="Port number to use (default: 8000)"
    )
    parser.add_argument(
        "--model-name", 
        type=str, 
        help="Model Name"
    )

    # è§£æä¼ å…¥çš„å‚æ•°
    args = parser.parse_args()
    return args

args = parse_args()
# é…ç½® vLLM æ¨ç†æœåŠ¡çš„åœ°å€å’Œæ¨¡å‹å
VLLM_API_URL = f"http://{args.ip}:{args.port}/v1/chat/completions"
MODEL_NAME = args.model_name


# âœ… æµå¼è¯·æ±‚å‡½æ•°
def chat_with_model_streaming(user_input, history):
    messages = [{"role": "system", "content": "You are a helpful assistant."}]
    messages.append({"role": "user", "content": user_input})

    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "stream": True  # âœ… å¯ç”¨æµå¼è¾“å‡º
    }

    history = history or []  # åˆå§‹åŒ–å†å²è®°å½•
    bot_response = ""  # å­˜å‚¨é€æ­¥ç”Ÿæˆçš„å›ç­”

    try:
        # âœ… ä½¿ç”¨ requests çš„æµå¼è¯·æ±‚
        with requests.post(VLLM_API_URL, json=payload, stream=True) as response:
            response.raise_for_status()
            
            # âœ… é€å—è§£ææµå¼å“åº”
            for chunk in response.iter_lines():
                if chunk:
                    chunk_str = chunk.decode("utf-8").strip()
                    if chunk_str.startswith("data: "):
                        chunk_data = chunk_str[6:]  # å»æ‰ "data: " å‰ç¼€
                        if chunk_data != "[DONE]":
                            try:
                                chunk_json = json.loads(chunk_data)
                                delta = chunk_json["choices"][0]["delta"]
                                if "content" in delta:
                                    bot_response += delta["content"]
                                    # âœ… é€æ­¥æ›´æ–°èŠå¤©è®°å½•
                                    yield history + [(user_input, bot_response)], ""
                            except json.JSONDecodeError:
                                pass

    except Exception as e:
        bot_response = f"âŒ æ¨ç†å¤±è´¥: {str(e)}"
        yield history + [(user_input, bot_response)], ""

# æ„å»º Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ’¬ Web UI æ¥å…¥ vLLM æ¨¡å‹ï¼ˆæµå¼è¾“å‡ºï¼‰")
    chatbot = gr.Chatbot()
    txt = gr.Textbox(placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜", label="è¾“å…¥")
    clear = gr.Button("æ¸…é™¤")
    submit = gr.Button("æäº¤")

    # âœ… ä½¿ç”¨æµå¼å‡½æ•°
    submit.click(chat_with_model_streaming, [txt, chatbot], [chatbot, txt])
    txt.submit(chat_with_model_streaming, [txt, chatbot], [chatbot, txt])
    clear.click(lambda: ([], ""), [], [chatbot, txt])

demo.launch(server_name=args.ip)