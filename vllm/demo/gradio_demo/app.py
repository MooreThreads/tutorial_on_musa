import gradio as gr
import requests
import json
import argparse
import time
import gradio_musa


def parse_args():
    # åˆ›å»º ArgumentParser å¯¹è±¡
    parser = argparse.ArgumentParser(description="Start the vLLM server.")

    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--ip", 
        type=str, 
        default="0.0.0.0",  # å¦‚æœæ²¡æœ‰ä¼ å…¥--ipï¼Œä½¿ç”¨é»˜è®¤å€¼
        help="IP address to bind to (default: 0.0.0.0)"
    )

    parser.add_argument(
        "--port", 
        type=str, 
        default="8000",  # å¦‚æœæ²¡æœ‰ä¼ å…¥--portï¼Œä½¿ç”¨é»˜è®¤å€¼
        help="Port number to use (default: 8000)"
    )
    parser.add_argument(
        "--model-name", 
        type=str, 
        help="Model Name"
    )

    # è§£æä¼ å…¥çš„å‚æ•°
    args = parser.parse_args()
    return args

args = parse_args()
# é…ç½® vLLM æ¨ç†æœåŠ¡çš„åœ°å€å’Œæ¨¡å‹å
VLLM_API_URL = f"http://{args.ip}:{args.port}/v1/chat/completions"
MODEL_NAME = args.model_name


# âœ… æµå¼è¯·æ±‚å‡½æ•°
def chat_with_model_streaming(user_input, history):
    messages = [{"role": "system", "content": "You are a helpful assistant."}]
    messages.append({"role": "user", "content": user_input})

    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "stream": True  # âœ… å¯ç”¨æµå¼è¾“å‡º
    }

    history = history or []  # åˆå§‹åŒ–å†å²è®°å½•
    bot_response = ""  # å­˜å‚¨é€æ­¥ç”Ÿæˆçš„å›ç­”

    # âœ… è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    token_count = 0  # âœ… è®°å½•ç”Ÿæˆçš„ Token æ•°é‡
    first_token_time = None

    try:
        # âœ… ä½¿ç”¨ requests çš„æµå¼è¯·æ±‚
        with requests.post(VLLM_API_URL, json=payload, stream=True) as response:
            response.raise_for_status()
            
            # âœ… é€å—è§£ææµå¼å“åº”
            for chunk in response.iter_lines():
                if chunk:
                    chunk_str = chunk.decode("utf-8").strip()
                    if chunk_str.startswith("data: "):
                        chunk_data = chunk_str[6:]  # å»æ‰ "data: " å‰ç¼€
                        if chunk_data != "[DONE]":
                            try:
                                chunk_json = json.loads(chunk_data)
                                delta = chunk_json["choices"][0]["delta"]
                                if "content" in delta:
                                    bot_response += delta["content"]
                                    # âœ… é€æ­¥æ›´æ–°èŠå¤©è®°å½•
                                    token_count += 1  # âœ… æ¯ä¸ª Token è®¡æ•°  
                                    if first_token_time is None and token_count > 0:
                                        first_token_time = time.time()

                                    yield history + [(user_input, bot_response)], "", "æ¨ç†ä¸­..."
                            except json.JSONDecodeError:
                                pass
            # âœ… è®°å½•ç»“æŸæ—¶é—´ & è®¡ç®—æ—¶é•¿
            first_token_latency = first_token_time - start_time if first_token_time is not None else 0
            elapsed_time = time.time() - first_token_time
            tps = token_count / elapsed_time if elapsed_time > 0 else 0  # âœ… è®¡ç®— Tokens Per Second
            speed_text = f"â³ é¦–å­—å»¶è¿Ÿ: {first_token_latency:.2f} | â±ï¸  è€—æ—¶: {elapsed_time:.2f} ç§’ | ğŸ”¢ Tokens: {token_count} | âš¡ é€Ÿåº¦: {tps:.2f} TPS" # â³
            yield history + [(user_input, bot_response)], "", speed_text  # âœ… è¿”å›æ¨ç†é€Ÿåº¦

    except Exception as e:
        bot_response = f"âŒ æ¨ç†å¤±è´¥: {str(e)}"
        yield history + [(user_input, bot_response)], ""



# âœ… æ¸…é™¤èŠå¤©è®°å½• & è®¡æ—¶å™¨
def clear_chat():
    return [], "", "â³ é¦–å­—å»¶è¿Ÿ: 0.00 ç§’ | â±ï¸  è€—æ—¶: 0.00 ç§’ | ğŸ”¢ Tokens: 0 | âš¡ é€Ÿåº¦: 0.00 TPS"  # âœ… æ¸…ç©ºæ‰€æœ‰ UI

# æ„å»º Gradio ç•Œé¢
with gradio_musa.Blocks() as demo:
    # gr.Markdown("## ğŸ’¬ Web UI æ¥å…¥ vLLM æ¨¡å‹ï¼ˆæµå¼è¾“å‡ºï¼‰")
    chatbot = gr.Chatbot(label="Running on MTT S4000")
    msg_input = gr.Textbox(placeholder="è¯·è¾“å…¥ä½ çš„é—®é¢˜", label="è¾“å…¥...", lines=1, autofocus=True)

    speed_display = gr.Textbox(label="æ¨ç†é€Ÿåº¦", value="â³ é¦–å­—å»¶è¿Ÿ: 0.00 ç§’ | â±ï¸  è€—æ—¶: 0.00 ç§’ | ğŸ”¢ Tokens: 0 | âš¡ é€Ÿåº¦: 0.00 TPS", interactive=False)  # >âœ… æ˜¾ç¤ºæ¨ç†é€Ÿåº¦

    # clear = gr.Button("æ¸…é™¤")
    # submit = gr.Button("æäº¤")
    with gr.Row():
        submit_btn = gr.Button(value="æäº¤")
        clear_btn = gr.Button("æ¸…é™¤å†å²")  # âœ… æ·»åŠ æ¸…é™¤æŒ‰é’®

    # âœ… ä½¿ç”¨æµå¼å‡½æ•°
    msg_input.submit(chat_with_model_streaming, inputs=[msg_input, chatbot], outputs=[chatbot, msg_input, speed_display]) # âœ… æŒ‰ Enter è§¦å‘
    submit_btn.click(chat_with_model_streaming, inputs=[msg_input, chatbot], outputs=[chatbot, msg_input, speed_display]) # âœ… æŒ‰æŒ‰é’®è§¦å‘
    clear_btn.click(clear_chat, inputs=[], outputs=[chatbot, msg_input, speed_display])  # âœ… æ¸…é™¤èŠå¤© & è®¡æ—¶

demo.queue()  # âœ… å…è®¸æµå¼æ•°æ®ä¼ è¾“
demo.launch(server_name=args.ip)